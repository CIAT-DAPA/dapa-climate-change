source = "INMET"
} else if (dst == "PER") {
source = "SENAMHI"
}
stCod <- data.frame(Station=names(monDt[4:length(monDt)]))
# Select stations within region
join <- merge(stCod, stInfo, by = "Station", all = FALSE)
posXY = join$Lon < xmin(rgExt) | join$Lon > xmax(rgExt) | join$Lat < ymin(rgExt) | join$Lat > ymax(rgExt)
join <- join[!posXY, ]
if (dst == "COL"){
joinSt <- cbind(join[ , c("Station", "Name","Lat", "Lon", "Alt")], "Source"=source)
joinDt <- cbind("Year"=monDt$Year, "Month"=monDt$Month,"Day"=monDt$Day, monDt[, which(names(monDt) %in% as.vector(join$Station))], digits = 1 )
} else {
joinSt <- rbind(joinSt, cbind("Station"=as.character(join$Station), "Name"=as.character(join$Name), "Lat"=join$Lat, "Lon"=join$Lon, "Alt"=join$Alt, "Source"=source))
joinDt <- cbind(joinDt, monDt[, which(names(monDt) %in% as.vector(join$Station))] )
}
}
# Write daily quality controled merged
write.csv(joinDt, paste0(oDir, "/", var, "_daily_all_qc_amazon.csv"), row.names = F)
write.csv(joinSt, paste0(oDir, "/", var, "_stations_daily_amazon.csv"), row.names = F)
}
#################################
### 02- Merge dataset monthly ###
#################################
merge_dst_mth <- function(bDir="Z:/DATA/WP2/01_Weather_Stations", var="prec", rg=c(-79.5, -72, -11.9, 3), sY=1971, fY=2010, rgname, oDir="Z:/DATA/WP2/04_Evaluations/WTH_ST"){
library(reshape)
require(raster)
# Set region extent
rgExt <- extent(rg)
dstList <- c("COL", "ECU", "GHCN", "GSOD", "PER", "BRA")
for (dst in dstList){
cat(dst, var, "merging\n")
# Read monthly weather file & select years
monDt <- read.csv(paste0(bDir, "/", dst, "/", var, "_monthly_all.csv"), header = T)
monDt <- monDt[ which(monDt$Year >= sY & monDt$Year <= fY),]
monDt$year <- NULL
monDt$month <- NULL
monDt$day <- NULL
# Read Station info file
stInfo <- read.csv(paste0(bDir, "/", dst, "/stations.csv"), header = T)
# Read name by dataset
if (dst == "COL"){
names(monDt) <- gsub("X", "", names(monDt))
source = "IDEAM"
} else if (dst == "GHCN"){
names(monDt) <- gsub("X", "", names(monDt))
names(stInfo) <- c("Station", "Lat", "Lon", "Alt", "Name")
source = "GHCN"
} else if (dst == "ECU") {
source = "INAMHI"
} else if (dst == "GSOD") {
names(monDt) <- gsub("X", "", names(monDt))
source = "GSOD"
} else if (dst == "BRA") {
source = "INMET"
names(monDt) <- gsub("X", "", names(monDt))
} else if (dst == "PER") {
source = "SENAMHI"
names(monDt) <- gsub("X", "", names(monDt))
stInfo$Station <-  sprintf("%06d", stInfo$Station)
}
stCod <- data.frame(Station=names(monDt[3:length(monDt)]))
# Select stations within region
join <- merge(stCod, stInfo, by = "Station", all = FALSE)
posXY = join$Lon < xmin(rgExt) | join$Lon > xmax(rgExt) | join$Lat < ymin(rgExt) | join$Lat > ymax(rgExt)
join <- join[!posXY, ]
if (dst == "COL"){
joinSt <- cbind(join[ , c("Station", "Name","Lat", "Lon", "Alt")], "Source"=source, "Country"=dst)
joinDt <- cbind("Year"=monDt$Year, "Month"=monDt$Month, monDt[, which(names(monDt) %in% as.vector(join$Station))])
# Count number of station available
# cat(ncol(monDt[, which(names(monDt) %in% as.vector(join$Station))]))
} else {
joinSt <- rbind(joinSt, cbind("Station"=as.character(join$Station), "Name"=as.character(join$Name), "Lat"=join$Lat, "Lon"=join$Lon, "Alt"=join$Alt, "Source"=source, "Country"=dst))
joinDt <- cbind(joinDt, monDt[, which(names(monDt) %in% as.vector(join$Station))])
# Count number of station available
# cat(ncol(monDt[, which(names(monDt) %in% as.vector(join$Station))]))
}
}
# Write daily quality controled merged
write.csv(joinDt, paste0(oDir, "/", var, "_monthly_all_amazon.csv"), row.names = F)
write.csv(joinSt, paste0(oDir, "/", var, "_stations_monthly_amazon.csv"), row.names = F)
}
#############################
### 03- Climatology Calcs ###
#############################
clim_calc <- function(var="prec",  bDir = "Z:/DATA/WP2/01_Weather_Stations/MERGE", oDir = "Z:/DATA/WP2/01_Weather_Stations/MERGE", stDir="Z:/DATA/WP2/01_Weather_Stations/MERGE", sY=1981, fY=2010){
# Read monthly file
monthly_var <- read.csv(paste0(bDir, "/", var, "_monthly_all_amazon.csv"), header=T)
oDir_per <- paste0(oDir, "/", sY, "_", fY)
if (!file.exists(oDir_per)) {dir.create(oDir_per, recursive = TRUE)}
if (var == "prec"){varmod <- "rain"} else { varmod = var}
## Climatology aggregation based on NA percent
avg_var = function(a,na.rm=T){
na.x = length(which(is.na(a))) / length(a)
if(na.x>=0.33){
x = NA
}else{
x = mean(a, na.rm = any(!is.na(a)))
}
return(x)
}
## Return %NA
na_per <- function(a,na.rm=T){
na.x = length(which(is.na(a))) / length(a)
x = na.x
return(x)
}
# Years selection
monthly_var <- monthly_var[ which(monthly_var$Year >= sY & monthly_var$Year <= fY),]
# Period climatology calc
monthly_avg = aggregate(monthly_var[,3:length(monthly_var)], list(Month=monthly_var$Month),avg_var)
na_p <- round( (1- apply(monthly_var[,3:length(monthly_var)], 2, na_per)) * (fY-sY), digits = 0)
# Remove unnecesary columns if exists
monthly_avg$month <- NULL;  monthly_avg$Month <- NULL;  monthly_avg$year <- NULL
# Transpose
st_names <- as.data.frame(names(monthly_avg))
monthly_avg <- cbind(st_names, round(t(monthly_avg), 1))
# Remove all rows with NA
monthly_avg <- monthly_avg[rowSums(is.na(monthly_avg[,2:ncol(monthly_avg)])) < 12, ]
# Add month names
mths <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
colnames(monthly_avg) <- c("Station", mths)
monthly_avg$Station <- gsub("X", "", monthly_avg$Station)
rownames(monthly_avg) <- NULL
## Add station info
stInfo <- read.csv(paste0(stDir, "/", var, "_stations_monthly_amazon.csv"), header=T)
join <- merge(stInfo, monthly_avg, by = "Station", all = FALSE)
## NA percent
na_p <- cbind(st_names, na_p)
names(na_p) <- c("Station", "NYEARS")
na_p$Station <-  gsub("X", "", na_p$Station)
join <- merge(join, na_p, by = "Station", all = FALSE)
join[is.na(join)] <- -9999.9
# Combine info and data
climData <- cbind(join[ , c("Station", "Source", "Station", "Name", "Country","Lon", "Lat", "Alt", "Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec", "NYEARS")])
names(climData) <- c("ID", "SOURCE", "OLD_ID","NAME","COUNTRY","LONG","LAT","ALT","JAN","FEB","MAR","APR","MAY","JUN","JUL","AUG","SEP","OCT","NOV","DEC","NYEARS")
# Write climatology
write.csv(climData, paste0(oDir_per, "/", varmod, "_amz.csv"), row.names=F)
}
var="prec"
bDir = "Z:/DATA/WP2/01_Weather_Stations/MERGE"
oDir = "Z:/DATA/WP2/01_Weather_Stations/MERGE"
stDir="Z:/DATA/WP2/01_Weather_Stations/MERGE"
sY=1981
fY=2010
monthly_var <- read.csv(paste0(bDir, "/", var, "_monthly_all_amazon.csv"), header=T)
monthly_var <- monthly_var[ which(monthly_var$Year >= sY & monthly_var$Year <= fY),]
station_data <- read.csv(paste0(bDir, "/", var, "_monthly_all_amazon.csv"), header=T)
station_coord <- read.csv(paste0(stDir, "/", var, "_stations_monthly_amazon.csv"), header=T)
monthly_var <- monthly_var[ which(monthly_var$Year >= sY & monthly_var$Year <= fY),]
chirps_all = stack(chirps_stk)
chirps_stk = "S:/observed/gridded_products/chirps/monthly/stack_chirps.grd"
chirps_all = stack(chirps_stk)
library(raster)
chirps_all = stack(chirps_stk)
View(station_coord)
y=cbind(station_coord$Lon, station_coord$Lat)
View(y)
station_chirps.b = raster::extract(x=chirps_all, y=cbind(station_coord$Lon, station_coord$Lat), method = 'bilinear')
bDir="Z:/DATA/WP2/01_Weather_Stations"
rg=c(-79.5, -70, -11, 2)
# rg <- c(-80, -66, -16, 5)
rgname <- "amazon"
sY=1981
fY=2010
oDir="Z:/DATA/WP2/01_Weather_Stations/MERGE"
varList <- c("prec", "tmax", "tmin")
var <- varList[1]
library(reshape)
require(raster)
# Set region extent
rgExt <- extent(rg)
dstList <- c("COL", "ECU", "GHCN", "GSOD", "PER", "BRA")
for (dst in dstList){
cat(dst, var, "merging\n")
# Read monthly weather file & select years
monDt <- read.csv(paste0(bDir, "/", dst, "/", var, "_monthly_all.csv"), header = T)
monDt <- monDt[ which(monDt$Year >= sY & monDt$Year <= fY),]
monDt$year <- NULL
monDt$month <- NULL
monDt$day <- NULL
# Read Station info file
stInfo <- read.csv(paste0(bDir, "/", dst, "/stations.csv"), header = T)
# Read name by dataset
if (dst == "COL"){
names(monDt) <- gsub("X", "", names(monDt))
source = "IDEAM"
} else if (dst == "GHCN"){
names(monDt) <- gsub("X", "", names(monDt))
names(stInfo) <- c("Station", "Lat", "Lon", "Alt", "Name")
source = "GHCN"
} else if (dst == "ECU") {
source = "INAMHI"
} else if (dst == "GSOD") {
names(monDt) <- gsub("X", "", names(monDt))
source = "GSOD"
} else if (dst == "BRA") {
source = "INMET"
names(monDt) <- gsub("X", "", names(monDt))
} else if (dst == "PER") {
source = "SENAMHI"
names(monDt) <- gsub("X", "", names(monDt))
stInfo$Station <-  sprintf("%06d", stInfo$Station)
}
stCod <- data.frame(Station=names(monDt[3:length(monDt)]))
# Select stations within region
join <- merge(stCod, stInfo, by = "Station", all = FALSE)
posXY = join$Lon < xmin(rgExt) | join$Lon > xmax(rgExt) | join$Lat < ymin(rgExt) | join$Lat > ymax(rgExt)
join <- join[!posXY, ]
if (dst == "COL"){
joinSt <- cbind(join[ , c("Station", "Name","Lat", "Lon", "Alt")], "Source"=source, "Country"=dst)
joinDt <- cbind("Year"=monDt$Year, "Month"=monDt$Month, monDt[, which(names(monDt) %in% as.vector(join$Station))])
# Count number of station available
# cat(ncol(monDt[, which(names(monDt) %in% as.vector(join$Station))]))
} else {
joinSt <- rbind(joinSt, cbind("Station"=as.character(join$Station), "Name"=as.character(join$Name), "Lat"=join$Lat, "Lon"=join$Lon, "Alt"=join$Alt, "Source"=source, "Country"=dst))
joinDt <- cbind(joinDt, monDt[, which(names(monDt) %in% as.vector(join$Station))])
# Count number of station available
# cat(ncol(monDt[, which(names(monDt) %in% as.vector(join$Station))]))
}
}
write.csv(joinDt, paste0(oDir, "/", var, "_monthly_all_amazon.csv"), row.names = F)
joinDt[1,]
t(joinDt[1,])
names(joinDt)
stSel <- names(joinDt[,-2])
stSel
stSel <- names(joinDt[,-3])
stSel <- "Stations"=names(joinDt[,-3])
stSel <- names(joinDt[,-3])
stSel <- as.matrix(names(joinDt[,-3]))
View(stSel)
stSel <- as.matrix(names(joinDt[,-3]))
View(stSel)
stSel <- as.matrix(names(joinDt[-3,]))
View(stSel)
stSel <- as.matrix(names(joinDt)[-3])
View(stSel)
stSel <- as.matrix(names(joinDt)[3:length(names(joinDt))])
View(stSel)
stSel <- as.matrix("Stations"=names(joinDt)[3:length(names(joinDt))]))
stSel <- as.matrix("Stations"=names(joinDt)[3:length(names(joinDt))])
stSel <- as.matrix(names(joinDt)[3:length(names(joinDt))])
View(stSel)
names(stSel) <- "Station"
View(stSel)
colnames(stSel) <- "Station"
View(stSel)
joinSt <- merge(stSel, joinSt, by = "Station", all = FALSE)
joinSt <- merge(joinSt, stSel, by = "Station", all = FALSE)
library(reshape)
require(raster)
# Set region extent
rgExt <- extent(rg)
dstList <- c("COL", "ECU", "GHCN", "GSOD", "PER", "BRA")
for (dst in dstList){
cat(dst, var, "merging\n")
# Read monthly weather file & select years
monDt <- read.csv(paste0(bDir, "/", dst, "/", var, "_monthly_all.csv"), header = T)
monDt <- monDt[ which(monDt$Year >= sY & monDt$Year <= fY),]
monDt$year <- NULL
monDt$month <- NULL
monDt$day <- NULL
# Read Station info file
stInfo <- read.csv(paste0(bDir, "/", dst, "/stations.csv"), header = T)
# Read name by dataset
if (dst == "COL"){
names(monDt) <- gsub("X", "", names(monDt))
source = "IDEAM"
} else if (dst == "GHCN"){
names(monDt) <- gsub("X", "", names(monDt))
names(stInfo) <- c("Station", "Lat", "Lon", "Alt", "Name")
source = "GHCN"
} else if (dst == "ECU") {
source = "INAMHI"
} else if (dst == "GSOD") {
names(monDt) <- gsub("X", "", names(monDt))
source = "GSOD"
} else if (dst == "BRA") {
source = "INMET"
names(monDt) <- gsub("X", "", names(monDt))
} else if (dst == "PER") {
source = "SENAMHI"
names(monDt) <- gsub("X", "", names(monDt))
stInfo$Station <-  sprintf("%06d", stInfo$Station)
}
stCod <- data.frame(Station=names(monDt[3:length(monDt)]))
# Select stations within region
join <- merge(stCod, stInfo, by = "Station", all = FALSE)
posXY = join$Lon < xmin(rgExt) | join$Lon > xmax(rgExt) | join$Lat < ymin(rgExt) | join$Lat > ymax(rgExt)
join <- join[!posXY, ]
if (dst == "COL"){
joinSt <- cbind(join[ , c("Station", "Name","Lat", "Lon", "Alt")], "Source"=source, "Country"=dst)
joinDt <- cbind("Year"=monDt$Year, "Month"=monDt$Month, monDt[, which(names(monDt) %in% as.vector(join$Station))])
# Count number of station available
# cat(ncol(monDt[, which(names(monDt) %in% as.vector(join$Station))]))
} else {
joinSt <- rbind(joinSt, cbind("Station"=as.character(join$Station), "Name"=as.character(join$Name), "Lat"=join$Lat, "Lon"=join$Lon, "Alt"=join$Alt, "Source"=source, "Country"=dst))
joinDt <- cbind(joinDt, monDt[, which(names(monDt) %in% as.vector(join$Station))])
# Count number of station available
# cat(ncol(monDt[, which(names(monDt) %in% as.vector(join$Station))]))
}
}
# Write daily quality controled merged
write.csv(joinDt, paste0(oDir, "/", var, "_monthly_all_amazon.csv"), row.names = F)
stSel <- as.matrix(names(joinDt)[3:length(names(joinDt))])
colnames(stSel) <- "Station"
joinSt_f <- merge(joinSt, stSel, by = "Station", all = FALSE)
length(stSel)
nrow(joinSt)
ncol(joinSt)
ncol(joinDt)
View(joinSt_f)
joinSt_f <- merge(stSel, joinSt, by = "Station", all = FALSE)
View(joinSt_f)
joinSt_f <- merge(stSel, joinSt, by = "Station", all = TRUE)
View(joinSt_f)
joinSt_f <- merge(stSel, joinSt, by = "Station", all = FALSE)
bDir <- "D:/CIAT/Projects/col-usaid/01_weather_stations"
var <- "rain"
bDir <- "D:/CIAT/Projects/col-usaid/01_weather_stations"
var <- "rain"
bDir <- "D:/CIAT/Projects/col-usaid/01_weather_stations"
var <- "rain"
st_data <- read.csv(paste0(bDir, "/", var, "rain_ris_1980.csv"), header=T)
st_data <- read.csv(paste0(bDir, "/", var, "_ris_1980.csv"), header=T)
raster("Y:/Product_6_resilient_coffee/02-monthly-interpolations/region/alt-prj-ris.asc")
require(raster)
raster("Y:/Product_6_resilient_coffee/02-monthly-interpolations/region/alt-prj-ris.asc")
raster("Y:/Product_6_resilient_coffee/02-monthly-interpolations/region/500m/alt-prj-ris.asc")
raster("Y:/Product_6_resilient_coffee/02-monthly-interpolations/region/500m_v2/alt-prj-ris.asc")
st_data <- read.csv(paste0(bDir, "/", var, "_ris_1980.csv"), header=T)
mthLs <- c("Jan", "Feb", "Mar", "Apr", "May", "Jun", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec")
mask <- raster(paste0(rDir, "/alt-prj-ris.asc"))
rDir <- "D:/CIAT/Projects/col-usaid/02_monthly_interpolation/region/500m_v3"
require(raster)
require(rgdal)
require(dismo)
require(som)
mask <- raster(paste0(rDir, "/alt-prj-ris.asc"))
refExt <- extent(mask)
raw_data <- read.csv(paste0(bDir, "/", var, "_ris_1980.csv"), header=T)
wgRs <- setMinMax(raster(paste0(rDir, "/rg_weigth_1deg_", var, ".tif")))
wgRs
plot(wgRs)
gap <- rasterize(cbind(raw_data$LONG, raw_data$LAT), mask, 1, fun=mean)
gap
plot(gap)
gap[is.na(gap)] <- 0
gap[gap==1] <- NA
plot(gap)
wgRs
plot(wgRs)
gap <- rasterize(cbind(raw_data$LONG, raw_data$LAT), mask, 1, fun=mean)
plot(gap)
cbind(raw_data$LONG, raw_data$LAT)
mask <- raster(paste0(rDir, "/alt-prj-ris.asc"))
mask
gap <- rasterize(cbind(raw_data$LONG, raw_data$LAT), mask, 1, fun=mean)
plot(gap)
plot(mask)
points(cbind(raw_data$LONG, raw_data$LAT))
gap <- rasterize(cbind(raw_data$LONG, raw_data$LAT), mask, 1, fun=mean)
gap
gap[is.na(gap)] <- 0
gap[gap==1] <- NA
plot(gap)
wgGap <- mask(1-(wgRs/(maxValue(wgRs)- minValue(wgRs))), resample(gap, wgRs))
plot(wgGap)
gap
wgGap
wgRs
denPres <- nrow(raw_data)/length(gap[!is.na(gap)])
denPres
npts <- length(mask[!is.na(mask)]) * denPres
npts
pts <- randomPoints(wgGap, n=npts, ext=refExt, prob=T)
refExt <- extent(mask)
pts <- randomPoints(wgGap, n=npts, ext=refExt, prob=T)
pts
points(pts)
npts
nrow(raw_data)
points(pts, pch=10)
write.csv(pts,  paste0(rDir, "/rain_ris_pseudost.csv"), row.names = F)
bDir <- "D:/CIAT/Projects/col-usaid/01_weather_stations"
rDir <- "D:/CIAT/Projects/col-usaid/02_monthly_interpolation/region/500m_v3"
var <- "tmin"
raw_data <- read.csv(paste0(bDir, "/", var, "_ris_1980.csv"), header=T)
mask <- raster(paste0(rDir, "/alt-prj-ris.asc"))
# depLim <- raster(paste0(rDir, "/rg_poly_amz"))
refExt <- extent(mask)
gap <- rasterize(cbind(raw_data$LONG, raw_data$LAT), mask, 1, fun=mean)
gap[is.na(gap)] <- 0
gap[gap==1] <- NA
wgRs <- setMinMax(raster(paste0(rDir, "/rg_weigth_1deg_", var, ".tif")))
wgGap <- mask(1-(wgRs/(maxValue(wgRs)- minValue(wgRs))), resample(gap, wgRs))
denPres <- nrow(raw_data)/length(gap[!is.na(gap)])
npts <- length(mask[!is.na(mask)]) * denPres
npts
pllot(wgGap)
plot(wgGap)
pts <- randomPoints(wgGap, n=npts, ext=refExt, prob=T)
gap <- rasterize(cbind(raw_data$LONG, raw_data$LAT), mask, 1, fun=mean)
gap[is.na(gap)] <- 0
gap[gap==1] <- NA
wgRs <- setMinMax(raster(paste0(rDir, "/rg_weigth_1deg_", var, ".tif")))
wgGap <- mask(1-(wgRs/(maxValue(wgRs)- minValue(wgRs))), resample(gap, wgRs))
wgGap
mask
wgRs <- setMinMax(raster(paste0(rDir, "/rg_weigth_1deg_", var, ".tif")))
wgGap <- mask(1-(wgRs/(maxValue(wgRs)- minValue(wgRs))), resample(gap, mask))
wgGap <- mask(1-(wgRs/(maxValue(wgRs)- minValue(wgRs))), resample(gap, wgRs))
wgGap
mask
plot(wgGap)
mask * 0
plot(mask * 0)
plot((mask * 0) + wgGap)
bDir <- "D:/CIAT/Projects/col-usaid/01_weather_stations"
rDir <- "D:/CIAT/Projects/col-usaid/02_monthly_interpolation/region/500m_v3"
var <- "tmin"
# Read monthly and station adn year selection
raw_data <- read.csv(paste0(bDir, "/", var, "_ris_1980.csv"), header=T)
## Region mask
mask <- raster(paste0(rDir, "/alt-prj-ris.asc"))
# depLim <- raster(paste0(rDir, "/rg_poly_amz"))
refExt <- extent(mask)
# Gap mask calcs
gap <- rasterize(cbind(raw_data$LONG, raw_data$LAT), mask, 1, fun=mean)
gap[is.na(gap)] <- 0
gap[gap==1] <- NA
wgRs <- setMinMax(raster(paste0(rDir, "/rg_weigth_1deg_", var, ".tif")))
wgGap <- mask(1-(wgRs/(maxValue(wgRs)- minValue(wgRs))), resample(gap, wgRs))
denPres <- nrow(raw_data)/length(gap[!is.na(gap)])
npts <- length(mask[!is.na(mask)]) * denPres
npts
plot(wgGap)
pts <- randomPoints(wgGap, n=npts, ext=refExt, prob=T)
points(pts)
write.csv(pts,  paste0(rDir, "/", var, "_ris_pseudost.csv"), row.names = F)
install.packages("sci")
install.packages("SCI")
require(SCI)
pr <- stack("D:/CIAT/Projects/wocat/AR5_Global_Daily_25k/ACCESS1-0/junk/prmm_day_BCSD_historical_r1i1p1_ACCESS1-0_1950.nc4")
require(raster)
pr <- stack("D:/CIAT/Projects/wocat/AR5_Global_Daily_25k/ACCESS1-0/junk/prmm_day_BCSD_historical_r1i1p1_ACCESS1-0_1950.nc4")
spi.para <- fitSCI(pr, first.mon=1, time.scale=6, distr="gamma", p0=TRUE)
extract(pr, c(-76,4))
install.packages("climate_summaries")
require(climate_summaries)
install.packages("precintcon")
require(precintcon)
spi(pr, period=3)
gcmList <- c("ACCESS1-0", "bcc-csm1-1", "BNU-ESM", "CanESM2", "CCSM4", "CESM1-BGC", "CNRM-CM5", "CSIRO-Mk3-6-0", "ensemble", "GFDL-CM3", "GFDL-ESM2G", "GFDL-ESM2M", "inmcm4",
"IPSL-CM5A-LR", "IPSL-CM5A-MR", "MIROC-ESM", "MIROC-ESM-CHEM", "MIROC5", "MPI-ESM-LR", "MPI-ESM-MR", "MRI-CGCM3", "NorESM1-M")
rcp <- "historical"
iY <- 1961
eY <- 1999
gcm <- gcmList[1]
iDir <- paste0("D:/CIAT/Projects/wocat/AR5_Global_Daily_25k/out_stats/", gcm)
pr_stk <- stack(paste0(iDir, "/PTOT_BCSD_", rcp, "_", gcm, "_", iY, "_", eY, ".monthly.nc"))
pr_stk(1:12)
pr_stk[[1:12]]
pr <- pr_stk[[1:12]]
extract(pr, c(-76,4))
-76 + 180
spi.para <- fitSCI(extract(pr, c(104,4)), first.mon=1, time.scale=6, distr="gamma", p0=TRUE)
extract(pr, c(-76,4))
extract(pr, c(104,4))
plot(pr)
plot(pr)
plot(pr[[1]])
plot(pr[[1]])
extract(pr, c(-76,0))
extract(pr, c(-74.41, 9.58))
points(c(-74.41, 9.58))
points(cbind(-74.41, 9.58))
points(cbind(-74.41, 0))
extract(pr, cbind(-74, 0))
spi.para <- fitSCI(extract(pr, cbind(-74, 0)), first.mon=1, time.scale=6, distr="gamma", p0=TRUE)
spi.para
extract(pr, cbind(-74, 0))
extract(pr, cbind(-74, 0))
as.vector(extract(pr, cbind(-74, 0)))
as.vector(extract(pr, cbind(-74, 0)))
spi.para <- fitSCI(as.vector(extract(pr, cbind(-74, 0))), first.mon=1, time.scale=6, distr="gamma", p0=TRUE)
spi.para
?spi
UseMethod("spi")
getAnywhere(spi)
getMethod("spi")
i <- 1
seq(i, nYears * i, 12)
iY <- 1961
eY <- 1999
seq(i, nYears * i, 12)
nYears <- eY - iY + 1
seq(i, nYears * i, 12)
nYears
seq(i, nYears * 12, 12)
pr_stk
i <- 12
seq(i, nYears * 12, 12)
a <- c(1,4,5,6,7,8,6,4)
b <- c(1,2,3,4)
a/b
stack()
anom_stk <- stack(nlayers=nlayers(pr_stk))
?stack
anom_stk <- stack(layers=nlayers(pr_stk))
a - b
